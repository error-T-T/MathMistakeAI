"""
AIå¼•æ“æ¨¡å—ï¼ˆçœŸå®Ollamaé›†æˆç‰ˆæœ¬ï¼‰
ä½œè€…: Rookie (error-T-T) & è‰¾å¯å¸Œé›…
GitHub ID: error-T-T
å­¦æ ¡é‚®ç®±: RookieT@e.gzhu.edu.cn
"""

import os
import json
import random
import httpx
from typing import Dict, Any, Optional
from .data_models import AnalysisRequest, AnalysisResponse

class AIEngine:
    """AIå¼•æ“ï¼ˆçœŸå®Ollamaé›†æˆç‰ˆæœ¬ï¼‰"""

    def __init__(self, base_url: str = None, model: str = None):
        """åˆå§‹åŒ–AIå¼•æ“"""
        self.base_url = base_url or os.getenv("OLLAMA_BASE_URL", "http://localhost:11434")
        self.model = model or os.getenv("OLLAMA_MODEL", "qwen2.5:7b")
        self.is_connected = False
        self.client = httpx.Client(timeout=30.0)  # 30ç§’è¶…æ—¶
        self.fallback_mode = False  # æ˜¯å¦å¯ç”¨æ¨¡æ‹Ÿå›é€€
        self._test_connection()

    def _test_connection(self):
        """æµ‹è¯•AIæœåŠ¡è¿æ¥ï¼ˆçœŸå®è¿æ¥æµ‹è¯•ï¼‰"""
        try:
            print(f"ğŸ¤– å°è¯•è¿æ¥AIæœåŠ¡: {self.base_url}")
            print(f"ğŸ“š ä½¿ç”¨æ¨¡å‹: {self.model}")

            # æµ‹è¯•Ollama APIè¿æ¥
            response = self.client.get(f"{self.base_url}/api/tags", timeout=5.0)
            if response.status_code == 200:
                models = response.json().get("models", [])
                model_names = [m["name"] for m in models]

                if self.model in model_names:
                    self.is_connected = True
                    self.fallback_mode = False
                    print(f"âœ… AIå¼•æ“åˆå§‹åŒ–å®Œæˆ - å·²è¿æ¥åˆ°æ¨¡å‹: {self.model}")
                else:
                    print(f"âš ï¸  æ¨¡å‹ {self.model} æœªæ‰¾åˆ°ï¼Œå¯ç”¨æ¨¡å‹: {model_names}")
                    print("âš ï¸  å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                    self.is_connected = False
                    self.fallback_mode = True
            else:
                print(f"âŒ OllamaæœåŠ¡å“åº”å¼‚å¸¸: {response.status_code}")
                print("âš ï¸  å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
                self.is_connected = False
                self.fallback_mode = True

        except Exception as e:
            print(f"âŒ AIæœåŠ¡è¿æ¥å¤±è´¥: {e}")
            print("âš ï¸  å°†ä½¿ç”¨æ¨¡æ‹Ÿæ¨¡å¼")
            self.is_connected = False
            self.fallback_mode = True

    def _generate_mock_analysis(self, request: AnalysisRequest) -> AnalysisResponse:
        """ç”Ÿæˆæ¨¡æ‹Ÿåˆ†æç»“æœï¼ˆå›é€€ç”¨ï¼‰"""
        error_types = [
            "æ¦‚å¿µç†è§£é”™è¯¯", "è®¡ç®—è¿‡ç¨‹é”™è¯¯", "å…¬å¼è®°å¿†é”™è¯¯",
            "å®¡é¢˜ä¸ä»”ç»†", "é€»è¾‘æ¨ç†é”™è¯¯", "ç¬¦å·ä½¿ç”¨é”™è¯¯"
        ]

        root_causes = [
            "å¯¹åŸºæœ¬æ¦‚å¿µç†è§£ä¸å¤Ÿæ·±å…¥",
            "è®¡ç®—è¿‡ç¨‹ä¸­ç²—å¿ƒå¤§æ„",
            "ç›¸å…³å…¬å¼è®°å¿†æ¨¡ç³Š",
            "é¢˜ç›®æ¡ä»¶ç†è§£ä¸åˆ°ä½",
            "æ¨ç†æ­¥éª¤å­˜åœ¨é€»è¾‘æ¼æ´",
            "æ•°å­¦ç¬¦å·ä½¿ç”¨ä¸è§„èŒƒ"
        ]

        knowledge_gaps_list = [
            ["å®šç§¯åˆ†æ¦‚å¿µ", "å¾®ç§¯åˆ†åŸºæœ¬å®šç†"],
            ["å¯¼æ•°è®¡ç®—è§„åˆ™", "é“¾å¼æ³•åˆ™"],
            ["ä¸‰è§’å‡½æ•°å…¬å¼", "è¯±å¯¼å…¬å¼"],
            ["æé™è®¡ç®—", "æ´›å¿…è¾¾æ³•åˆ™"],
            ["çŸ©é˜µè¿ç®—", "è¡Œåˆ—å¼è®¡ç®—"],
            ["å¾®åˆ†æ–¹ç¨‹æ±‚è§£", "åˆ†ç¦»å˜é‡æ³•"]
        ]

        suggestions = [
            "å»ºè®®å¤ä¹ ç›¸å…³åŸºç¡€æ¦‚å¿µï¼Œé€šè¿‡ä¾‹é¢˜åŠ æ·±ç†è§£",
            "å»ºè®®å¤šåšè®¡ç®—ç»ƒä¹ ï¼Œæé«˜è®¡ç®—å‡†ç¡®æ€§",
            "å»ºè®®æ•´ç†å¸¸ç”¨å…¬å¼ï¼Œå®šæœŸå¤ä¹ è®°å¿†",
            "å»ºè®®ä»”ç»†å®¡é¢˜ï¼Œæ ‡è®°å…³é”®æ¡ä»¶",
            "å»ºè®®å­¦ä¹ æ ‡å‡†è§£é¢˜æ­¥éª¤ï¼ŒåŸ¹å…»é€»è¾‘æ€ç»´",
            "å»ºè®®è§„èŒƒæ•°å­¦ç¬¦å·ä½¿ç”¨ï¼Œé¿å…æ··æ·†"
        ]

        examples = [
            "ç±»ä¼¼é¢˜ç›®ï¼šè®¡ç®—âˆ«(0 to Ï€) sin x dx",
            "ç±»ä¼¼é¢˜ç›®ï¼šæ±‚f(x)=x^2åœ¨x=1å¤„çš„å¯¼æ•°",
            "ç±»ä¼¼é¢˜ç›®ï¼šè®¡ç®—lim(xâ†’0) (1-cos x)/x^2",
            "ç±»ä¼¼é¢˜ç›®ï¼šè§£æ–¹ç¨‹dy/dx = 3x^2",
            "ç±»ä¼¼é¢˜ç›®ï¼šæ±‚çŸ©é˜µ[[2,1],[1,2]]çš„ç‰¹å¾å€¼"
        ]

        idx = random.randint(0, len(error_types) - 1)

        return AnalysisResponse(
            mistake_id=request.mistake_id,
            error_type=error_types[idx],
            root_cause=root_causes[idx],
            knowledge_gap=knowledge_gaps_list[idx],
            learning_suggestions=[suggestions[idx]],
            similar_examples=[random.choice(examples) for _ in range(3)],
            confidence_score=round(random.uniform(0.7, 0.95), 2)
        )

    def analyze_mistake(self, request: AnalysisRequest) -> AnalysisResponse:
        """åˆ†æé”™é¢˜ï¼ˆçœŸå®AIåˆ†æï¼‰"""
        if self.fallback_mode or not self.is_connected:
            print("âš ï¸  AIæœåŠ¡æœªè¿æ¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿåˆ†æ")
            return self._generate_mock_analysis(request)

        try:
            # æ„é€ ç³»ç»Ÿæç¤ºè¯
            system_prompt = """ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦æ•™è‚²AIåŠ©æ‰‹ï¼Œä¸“é—¨åˆ†æå­¦ç”Ÿçš„æ•°å­¦é”™é¢˜ã€‚
è¯·æ ¹æ®æä¾›çš„é”™é¢˜ä¿¡æ¯ï¼Œç”Ÿæˆè¯¦ç»†çš„åˆ†ææŠ¥å‘Šï¼Œå¿…é¡»ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¿”å›ï¼š

{
    "error_type": "é”™è¯¯ç±»å‹åˆ†ç±»ï¼ˆå¦‚ï¼šæ¦‚å¿µç†è§£é”™è¯¯ã€è®¡ç®—è¿‡ç¨‹é”™è¯¯ç­‰ï¼‰",
    "root_cause": "é”™è¯¯æ ¹æºåˆ†æ",
    "knowledge_gap": ["çŸ¥è¯†æ¼æ´1", "çŸ¥è¯†æ¼æ´2"],
    "learning_suggestions": ["å­¦ä¹ å»ºè®®1", "å­¦ä¹ å»ºè®®2"],
    "similar_examples": ["ç±»ä¼¼é¢˜ç›®ç¤ºä¾‹1", "ç±»ä¼¼é¢˜ç›®ç¤ºä¾‹2"],
    "confidence_score": 0.85
}

è¯·ç¡®ä¿confidence_scoreåœ¨0.7-0.95ä¹‹é—´ï¼Œè¡¨ç¤ºåˆ†æçš„ç½®ä¿¡åº¦ã€‚"""

            # æ„é€ ç”¨æˆ·æ¶ˆæ¯
            user_message = f"""è¯·åˆ†æä»¥ä¸‹æ•°å­¦é”™é¢˜ï¼š

é¢˜ç›®å†…å®¹: {request.question_content}
é”™è¯¯è¿‡ç¨‹: {request.wrong_process}
é”™è¯¯ç­”æ¡ˆ: {request.wrong_answer}
æ­£ç¡®ç­”æ¡ˆ: {request.correct_answer}

è¯·ä¸¥æ ¼æŒ‰ç…§ä¸Šè¿°JSONæ ¼å¼è¿”å›åˆ†æç»“æœã€‚"""

            # æ„é€ Ollama APIè¯·æ±‚
            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                "stream": False,
                "format": "json",  # è¦æ±‚è¿”å›JSONæ ¼å¼
                "options": {
                    "temperature": 0.3,  # è¾ƒä½æ¸©åº¦ä»¥è·å¾—æ›´ç¡®å®šæ€§çš„è¾“å‡º
                    "top_p": 0.9
                }
            }

            print(f"ğŸ“Š å‘é€AIåˆ†æè¯·æ±‚ï¼Œé”™é¢˜ID: {request.mistake_id}")

            # å‘é€è¯·æ±‚åˆ°Ollama
            response = self.client.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=60.0  # åˆ†æå¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´
            )

            if response.status_code == 200:
                result = response.json()
                content = result.get("message", {}).get("content", "")

                # å°è¯•è§£æJSONå“åº”
                try:
                    # æœ‰æ—¶æ¨¡å‹ä¼šåœ¨JSONå‰åæ·»åŠ é¢å¤–æ–‡æœ¬ï¼Œéœ€è¦æå–JSONéƒ¨åˆ†
                    if "```json" in content:
                        # æå–ä»£ç å—ä¸­çš„JSON
                        start_idx = content.find("```json") + 7
                        end_idx = content.find("```", start_idx)
                        json_str = content[start_idx:end_idx].strip()
                    elif "```" in content:
                        # æå–æ™®é€šä»£ç å—
                        start_idx = content.find("```") + 3
                        end_idx = content.find("```", start_idx)
                        json_str = content[start_idx:end_idx].strip()
                    else:
                        # ç›´æ¥å°è¯•è§£ææ•´ä¸ªå†…å®¹
                        json_str = content.strip()

                    analysis_data = json.loads(json_str)

                    # æ„å»ºAnalysisResponseå¯¹è±¡
                    return AnalysisResponse(
                        mistake_id=request.mistake_id,
                        error_type=analysis_data.get("error_type", "æœªçŸ¥é”™è¯¯ç±»å‹"),
                        root_cause=analysis_data.get("root_cause", "æœªçŸ¥é”™è¯¯æ ¹æº"),
                        knowledge_gap=analysis_data.get("knowledge_gap", []),
                        learning_suggestions=analysis_data.get("learning_suggestions", []),
                        similar_examples=analysis_data.get("similar_examples", []),
                        confidence_score=min(max(analysis_data.get("confidence_score", 0.8), 0.7), 0.95)
                    )

                except json.JSONDecodeError as e:
                    print(f"âŒ JSONè§£æå¤±è´¥: {e}")
                    print(f"ğŸ“ åŸå§‹å“åº”: {content[:200]}...")
                    print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æä½œä¸ºå›é€€")
                    return self._generate_mock_analysis(request)

            else:
                print(f"âŒ Ollama APIè¯·æ±‚å¤±è´¥: {response.status_code}")
                print(f"ğŸ“ å“åº”: {response.text}")
                print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æä½œä¸ºå›é€€")
                return self._generate_mock_analysis(request)

        except Exception as e:
            print(f"âŒ AIåˆ†æè¿‡ç¨‹ä¸­å‘ç”Ÿå¼‚å¸¸: {e}")
            print("âš ï¸  ä½¿ç”¨æ¨¡æ‹Ÿåˆ†æä½œä¸ºå›é€€")
            return self._generate_mock_analysis(request)

    def generate_practice_questions(self, knowledge_gaps: list, count: int = 5) -> list:
        """ç”Ÿæˆç»ƒä¹ é¢˜ï¼ˆçœŸå®AIç”Ÿæˆï¼‰"""
        print(f"ğŸ“ ä¸ºçŸ¥è¯†æ¼æ´ {knowledge_gaps} ç”Ÿæˆ {count} é“ç»ƒä¹ é¢˜")

        if self.fallback_mode or not self.is_connected:
            print("âš ï¸  AIæœåŠ¡æœªè¿æ¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return self._generate_mock_practice_questions(knowledge_gaps, count)

        try:
            # æ„é€ æç¤ºè¯
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦æ•™å¸ˆï¼Œè¯·æ ¹æ®ç»™å®šçš„çŸ¥è¯†æ¼æ´ç”Ÿæˆç»ƒä¹ é¢˜ã€‚"

            user_message = f"""è¯·ä¸ºä»¥ä¸‹çŸ¥è¯†æ¼æ´ç”Ÿæˆ{count}é“æ•°å­¦ç»ƒä¹ é¢˜ï¼š
çŸ¥è¯†æ¼æ´: {', '.join(knowledge_gaps)}

è¯·è¿”å›ä¸€ä¸ªJSONæ•°ç»„ï¼Œæ¯ä¸ªç»ƒä¹ é¢˜å¯¹è±¡åŒ…å«ä»¥ä¸‹å­—æ®µï¼š
{{
    "question": "é¢˜ç›®å†…å®¹",
    "answer": "æ­£ç¡®ç­”æ¡ˆ",
    "explanation": "è§£é¢˜æ€è·¯å’Œè§£é‡Š",
    "difficulty": "ç®€å•/ä¸­ç­‰/å›°éš¾"
}}"""

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                "stream": False,
                "format": "json"
            }

            response = self.client.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=60.0
            )

            if response.status_code == 200:
                result = response.json()
                content = result.get("message", {}).get("content", "")

                try:
                    # æå–å’Œè§£æJSON
                    json_str = content
                    if "```json" in content:
                        start_idx = content.find("```json") + 7
                        end_idx = content.find("```", start_idx)
                        json_str = content[start_idx:end_idx].strip()
                    elif "```" in content:
                        start_idx = content.find("```") + 3
                        end_idx = content.find("```", start_idx)
                        json_str = content[start_idx:end_idx].strip()

                    questions = json.loads(json_str)

                    # æ·»åŠ IDå’Œæ ‡ç­¾
                    for i, q in enumerate(questions):
                        q["id"] = f"PQ{i+1:03d}"
                        q["knowledge_tags"] = knowledge_gaps

                    return questions

                except json.JSONDecodeError:
                    print("âŒ ç»ƒä¹ é¢˜JSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                    return self._generate_mock_practice_questions(knowledge_gaps, count)

            else:
                print(f"âŒ ç”Ÿæˆç»ƒä¹ é¢˜å¤±è´¥: {response.status_code}")
                return self._generate_mock_practice_questions(knowledge_gaps, count)

        except Exception as e:
            print(f"âŒ ç”Ÿæˆç»ƒä¹ é¢˜å¼‚å¸¸: {e}")
            return self._generate_mock_practice_questions(knowledge_gaps, count)

    def _generate_mock_practice_questions(self, knowledge_gaps: list, count: int = 5) -> list:
        """ç”Ÿæˆæ¨¡æ‹Ÿç»ƒä¹ é¢˜ï¼ˆå›é€€ç”¨ï¼‰"""
        base_questions = [
            {
                "question": "è®¡ç®—å®šç§¯åˆ† âˆ«(0 to 1) x^3 dx",
                "answer": "1/4",
                "explanation": "ä½¿ç”¨å¹‚å‡½æ•°ç§¯åˆ†å…¬å¼ âˆ«x^n dx = x^(n+1)/(n+1)"
            },
            {
                "question": "æ±‚å‡½æ•° f(x) = 2x^2 - 3x + 1 çš„å¯¼æ•°",
                "answer": "f'(x) = 4x - 3",
                "explanation": "ä½¿ç”¨å¹‚å‡½æ•°æ±‚å¯¼å…¬å¼ (x^n)' = n*x^(n-1)"
            },
            {
                "question": "è®¡ç®—æé™ lim(xâ†’0) (e^x - 1)/x",
                "answer": "1",
                "explanation": "ä½¿ç”¨é‡è¦æé™æˆ–æ´›å¿…è¾¾æ³•åˆ™"
            },
            {
                "question": "è§£å¾®åˆ†æ–¹ç¨‹ dy/dx = 2y",
                "answer": "y = Ce^(2x)",
                "explanation": "ä½¿ç”¨åˆ†ç¦»å˜é‡æ³•ï¼Œç§¯åˆ†å¾—åˆ°ç»“æœ"
            },
            {
                "question": "è®¡ç®—çŸ©é˜µ [[1,2],[3,4]] + [[5,6],[7,8]]",
                "answer": "[[6,8],[10,12]]",
                "explanation": "çŸ©é˜µåŠ æ³•ï¼šå¯¹åº”å…ƒç´ ç›¸åŠ "
            }
        ]

        questions = []
        for i in range(min(count, len(base_questions))):
            q = base_questions[i].copy()
            q["id"] = f"PQ{i+1:03d}"
            q["knowledge_tags"] = knowledge_gaps[:2] if knowledge_gaps else ["åŸºç¡€æ•°å­¦"]
            q["difficulty"] = random.choice(["ç®€å•", "ä¸­ç­‰", "å›°éš¾"])
            questions.append(q)

        return questions

    def explain_concept(self, concept: str) -> Dict[str, Any]:
        """è§£é‡Šæ•°å­¦æ¦‚å¿µï¼ˆçœŸå®AIè§£é‡Šï¼‰"""
        print(f"ğŸ“š è§£é‡Šæ¦‚å¿µ: {concept}")

        if self.fallback_mode or not self.is_connected:
            print("âš ï¸  AIæœåŠ¡æœªè¿æ¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
            return self._generate_mock_concept_explanation(concept)

        try:
            system_prompt = "ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„æ•°å­¦æ•™å¸ˆï¼Œè¯·æ¸…æ™°è§£é‡Šæ•°å­¦æ¦‚å¿µã€‚"

            user_message = f"""è¯·è§£é‡Šæ•°å­¦æ¦‚å¿µï¼š{concept}

è¯·è¿”å›JSONæ ¼å¼ï¼š
{{
    "definition": "æ¦‚å¿µå®šä¹‰",
    "formula": "ç›¸å…³å…¬å¼ï¼ˆå¦‚æœæœ‰ï¼‰",
    "key_points": ["å…³é”®ç‚¹1", "å…³é”®ç‚¹2", "å…³é”®ç‚¹3"],
    "example": "ç¤ºä¾‹",
    "note": "å¤‡æ³¨"
}}"""

            payload = {
                "model": self.model,
                "messages": [
                    {"role": "system", "content": system_prompt},
                    {"role": "user", "content": user_message}
                ],
                "stream": False,
                "format": "json"
            }

            response = self.client.post(
                f"{self.base_url}/api/chat",
                json=payload,
                timeout=30.0
            )

            if response.status_code == 200:
                result = response.json()
                content = result.get("message", {}).get("content", "")

                try:
                    json_str = content
                    if "```json" in content:
                        start_idx = content.find("```json") + 7
                        end_idx = content.find("```", start_idx)
                        json_str = content[start_idx:end_idx].strip()
                    elif "```" in content:
                        start_idx = content.find("```") + 3
                        end_idx = content.find("```", start_idx)
                        json_str = content[start_idx:end_idx].strip()

                    explanation = json.loads(json_str)
                    explanation["concept"] = concept
                    return explanation

                except json.JSONDecodeError:
                    print("âŒ æ¦‚å¿µè§£é‡ŠJSONè§£æå¤±è´¥ï¼Œä½¿ç”¨æ¨¡æ‹Ÿæ•°æ®")
                    return self._generate_mock_concept_explanation(concept)

            else:
                print(f"âŒ è§£é‡Šæ¦‚å¿µå¤±è´¥: {response.status_code}")
                return self._generate_mock_concept_explanation(concept)

        except Exception as e:
            print(f"âŒ è§£é‡Šæ¦‚å¿µå¼‚å¸¸: {e}")
            return self._generate_mock_concept_explanation(concept)

    def _generate_mock_concept_explanation(self, concept: str) -> Dict[str, Any]:
        """ç”Ÿæˆæ¨¡æ‹Ÿæ¦‚å¿µè§£é‡Šï¼ˆå›é€€ç”¨ï¼‰"""
        concept_explanations = {
            "å®šç§¯åˆ†": {
                "definition": "å®šç§¯åˆ†æ˜¯å‡½æ•°åœ¨æŸä¸ªåŒºé—´ä¸Šçš„ç§¯åˆ†ï¼Œè¡¨ç¤ºæ›²çº¿ä¸‹çš„é¢ç§¯",
                "formula": "âˆ«[a,b] f(x) dx = F(b) - F(a)",
                "key_points": ["å¾®ç§¯åˆ†åŸºæœ¬å®šç†", "é»æ›¼å’Œ", "é¢ç§¯è®¡ç®—"],
                "example": "âˆ«(0 to 1) x^2 dx = 1/3",
                "note": "è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®"
            },
            "å¯¼æ•°": {
                "definition": "å¯¼æ•°æè¿°å‡½æ•°åœ¨æŸä¸€ç‚¹çš„å˜åŒ–ç‡",
                "formula": "f'(x) = lim(hâ†’0) [f(x+h)-f(x)]/h",
                "key_points": ["åˆ‡çº¿æ–œç‡", "æå€¼ç‚¹", "å•è°ƒæ€§"],
                "example": "f(x)=x^2, f'(x)=2x",
                "note": "è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®"
            },
            "æé™": {
                "definition": "æé™æè¿°å‡½æ•°åœ¨è‡ªå˜é‡è¶‹è¿‘æŸå€¼æ—¶çš„è¡Œä¸º",
                "formula": "lim(xâ†’a) f(x) = L",
                "key_points": ["è¿ç»­æ€§", "æ— ç©·å°", "é‡è¦æé™"],
                "example": "lim(xâ†’0) sin(x)/x = 1",
                "note": "è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®"
            }
        }

        if concept in concept_explanations:
            explanation = concept_explanations[concept].copy()
            explanation["concept"] = concept
            return explanation
        else:
            return {
                "concept": concept,
                "definition": f"{concept}æ˜¯æ•°å­¦ä¸­çš„é‡è¦æ¦‚å¿µ",
                "formula": "æš‚æ— æ ‡å‡†å…¬å¼",
                "key_points": ["åŸºæœ¬å®šä¹‰", "ç›¸å…³æ€§è´¨", "åº”ç”¨åœºæ™¯"],
                "example": "ç¤ºä¾‹æš‚ç¼º",
                "note": "è¿™æ˜¯æ¨¡æ‹Ÿæ•°æ®ï¼Œå®é™…ä½¿ç”¨éœ€è¦AIæ¨¡å‹ç”Ÿæˆ"
            }

    def health_check(self) -> Dict[str, Any]:
        """AIå¼•æ“å¥åº·æ£€æŸ¥"""
        return {
            "service": "MathMistakeAI AI Engine",
            "status": "healthy" if self.is_connected else "degraded",
            "model": self.model,
            "base_url": self.base_url,
            "connected": self.is_connected,
            "mode": "real" if self.is_connected and not self.fallback_mode else "mock",
            "message": "å·²è¿æ¥åˆ°çœŸå®AIæœåŠ¡" if self.is_connected and not self.fallback_mode else "æ¨¡æ‹Ÿæ¨¡å¼è¿è¡Œä¸­"
        }
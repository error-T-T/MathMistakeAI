# Ollama配置
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_MODEL=qwen2.5:7b
# 可用模型: qwen2.5:7b, gemma3:12b, llama3.1:8b

# 服务器配置
HOST=0.0.0.0
PORT=8000
DEBUG=true

# 数据文件路径
DATA_FILE_PATH=data/mistakes.csv
SAMPLE_DATA_PATH=sample_data/math_mistakes_sample.txt